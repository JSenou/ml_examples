{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Example using Blood Transfusion Service Center  Data Set\n",
    "## For 2017-03-11 Data Science with Python Study Group\n",
    "#### Dinesh Shenoy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows',1000)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Pick a data set.   UCI Machine Learning Library:  https://archive.ics.uci.edu/ml/datasets.html\n",
    "* See left-hand frame options for refining your search.\n",
    "* For this demo I searched for one with just a few features / predictors / attributes and a simple yes/no outcome to be classified:  \n",
    "    * **Blood Transfusion Service Center Data Set**:  https://archive.ics.uci.edu/ml/datasets/Blood+Transfusion+Service+Center\n",
    "* Other ones that looked interesting to me as potentially good examples for applying Logistic Regression to are:\n",
    "    * **Mammographic Mass Data Set**:  https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass\n",
    "    * **Banknote Authentication Data Set**:  https://archive.ics.uci.edu/ml/datasets/banknote+authentication#\n",
    "    * **Haberman's Survival Data Set**:  https://archive.ics.uci.edu/ml/datasets/Haberman%27s+Survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Blood Transfusion Service Center Data Set:  https://archive.ics.uci.edu/ml/datasets/Blood+Transfusion+Service+Center\n",
    "\n",
    "#### The predictors are:\n",
    "    * R = Recency = months since last donation\n",
    "    * F = Frequency = total number of donations\n",
    "    * M = Monetary = total blood donated in c.c. . . . huh???\n",
    "    * T = Time = months since first donation\n",
    "\n",
    "#### The response is:\n",
    "    * D = a binary variable representing whether he/she donated blood in March 2007: 0 = did not, 1 = did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine the data file before importing\n",
    "!head transfusion.data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data into a Pandas dataframe-- does Pandas figure out the headers?\n",
    "dat = pd.read_csv('transfusion.data.txt')\n",
    "\n",
    "print(dat.shape)\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# re-do, with shorter names for the columns and skip that first row\n",
    "cols = ['Recency','Frequency','Monetary','Time','Donated']\n",
    "\n",
    "dat = pd.read_csv('transfusion.data.txt',names=cols,skiprows=1)\n",
    "\n",
    "print(dat.shape)\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Take a quick look at the predictors, any issues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (18,10)\n",
    "dat.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things I note:\n",
    "    * The data might have been sorted by Recency, in two batches . . . not a big deal, if we split randomly.\n",
    "    * Frequency and Monetary appear suspiciously correlated.\n",
    "    * Donated = 0 seems much more common than Donated = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count the number of 0's and 1's in the response column \"Donated\"\n",
    "np.bincount(dat.Donated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the data types\n",
    "print(dat.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert the predictors to floats (maybe not necessary, but . . . )\n",
    "dat[dat.columns[:-1]] *= 1.0\n",
    "print(dat.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Double-check if any missing values (the notes on the data say no missing values, but . . . )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Slice the frame into a DataFrame for the predictors and a Series for the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = dat[cols[:-1]].copy()   \n",
    "response   = dat[cols[ -1]].copy()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 6. Check for correlations amongst the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize the correlation using pyplot.matshow() to display pandas.DataFrame.corr()\n",
    "def plot_corr(df, size=11):\n",
    "    \"\"\"\n",
    "    Plots correlation matrix for each pair of columns    \n",
    "    \"\"\"\n",
    "    corr = df.corr()\n",
    "    fig, ax = plt.subplots(figsize = (size,size))\n",
    "    cax = ax.matshow(corr)\n",
    "    fig.colorbar(cax, fraction=0.0458, pad=0.04)\n",
    "    plt.xticks(np.arange(len(corr.columns)), corr.columns)\n",
    "    plt.yticks(np.arange(len(corr.columns)), corr.columns)\n",
    "\n",
    "plot_corr(predictors, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# yeah, clearly one column was scaled from the other\n",
    "set( predictors.Monetary.values / predictors.Frequency.values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop the \"Monetary\" column\n",
    "del predictors['Monetary']\n",
    "predictors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Normalize the predictors:  http://scikit-learn.org/stable/modules/preprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (16,8)\n",
    "predictors.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "predictors = preprocessing.scale(predictors)\n",
    "\n",
    "# package the resulting array back into a DataFrame\n",
    "predictors = pd.DataFrame(data=predictors,index=np.arange(0,predictors.shape[0]),columns=['Recency','Frequency','Time'])\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16,8)\n",
    "predictors.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mean of each predictor is 0, std deviation is 1\n",
    "predictors.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 8.  Split the data into \"train\" and \"test\" sets\n",
    "#### Use `sklearn.model_selection.train_test_split()` to randomize the split.\n",
    "#### Use \"`X`\" for the matrix of predictors and \"`y`\" for the vector of responses, following the convention in the sklearn docs at http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_split_frac = 0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, response, \n",
    "                                                            test_size=test_split_frac, random_state=random_state)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To confirm the split was randomized, note the row indices\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# confirm they match up in the response (no scrambling of indices!)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for comparison with the confusion matrix below, count how many actual \"0\" and \"1\" responses\n",
    "# in the test data set\n",
    "n_true_positive = y_test.sum()\n",
    "n_true_negative = y_test.shape[0] - y_test.sum()\n",
    "n_true_positive, n_true_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 9. Train a LogisticRegression classifier on `X_train` and `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression()  # keep all the defaults \n",
    "\n",
    "lr_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 10. Test the model on `X_test` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_predict_test = lr_model.predict(X_test)\n",
    "lr_predict_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many incorrectly predicted response values out of 225?\n",
    "len(np.nonzero( y_test.values - lr_predict_test )[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Confusion matrix\n",
    "`sklearn.metrics.confusion_matrix()` generates a confusion matrix. Supplied with option `labels=[1,0]`, it produces a confusion matrix in which:\n",
    "\n",
    "![title](Binary_Classification_Matrix_Definition.png)\n",
    "(Image credit:  https://docs.wso2.com/display/ML100/Model+Evaluation+Measures)\n",
    "\n",
    "A *perfect* classifier's confusion matrix for this test data set should be:\n",
    "\n",
    "$$\\begin{bmatrix} 60 & 0 \\\\ 0 & 165 \\end{bmatrix}$$\n",
    "\n",
    "Compare to how we actually did . . . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# \"labels\" is a list of the response values: 1 or 0; put 1 first in the list to match layout shown above\n",
    "response_labels = [1,0]\n",
    "\n",
    "metrics.confusion_matrix(y_test, lr_predict_test, labels=response_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 12.  Recall (\"Sensitivity\") and Precision\n",
    "#### *Recall* (or \"sensitivity\") is how well the model is correctly predicting a \"1\" (did donate) when the person in fact did donate.  That is the number of true positives (TP) divided by the total actual positive (TP + FN == all that actually donated):  \n",
    "\n",
    "$$\\mbox{Recall} = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "Increasing recall would come through decreasing false negatives (FN).\n",
    "\n",
    "#### *Precision* is how often a person actually did donate when the model *said* it they donated.  That is the number of true positives (TP) divided by the total number of people the model said donated (TP + FP == all the people the model *said* donated):\n",
    "\n",
    "$$\\mbox{Precision} = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "Increasing precision would come through decreasing false positives (FP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get recall (and precision) as part of the classification report\n",
    "print(metrics.classification_report(y_test, lr_predict_test, labels=response_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the response class of \"0\", the recall is 98%, which sounds almost too good . .  .\n",
    "#### More importantly, for response class of \"1\", the recall is 8%.  We'd be better off flipping a coin!\n",
    "#### Re-examine the imbalance of \"0\" and \"1\" noted earlier in the data overall and in the training data specifically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"all data fraction of 1's = %.3f\" % (      1. * dat.Donated.values.sum() / dat.Donated.values.shape[0] ) )\n",
    "print(\"all data fraction of 0's = %.3f\" % ( 1. - 1. * dat.Donated.values.sum() / dat.Donated.values.shape[0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"y_train fraction of 1's = %.3f\" % (      1. * y_train.sum() / y_train.shape[0] ) )\n",
    "print(\"y_train fraction of 0's = %.3f\" % ( 1. - 1. * y_train.sum() / y_train.shape[0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and here's the raw count of 0's and 1's in the training data set\n",
    "np.bincount(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.  Unbalanced classes -- re-run with `LogisticRegression( class_weight='balanced' )`\n",
    "From the docs at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression:\n",
    "\n",
    "The “balanced” mode uses the values of y to automatically adjust weights inversely  proportional to class frequencies in the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(class_weight='balanced')  \n",
    "\n",
    "lr_model.fit(X_train,y_train)\n",
    "lr_predict_test = lr_model.predict(X_test)\n",
    "\n",
    "metrics.confusion_matrix(y_test, lr_predict_test, labels=response_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, lr_predict_test, labels=response_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. OPTIONAL:  Cross Validation\n",
    "    * Overfitting is a problem (in general, if not here)\n",
    "    * Cutting up the data into k-folds, training on the k-1 and testing on the kth should yield a more stable model\n",
    "\n",
    "![title](k-fold-cross-validation.jpg)\n",
    "(Image credit:  http://cse3521.artifice.cc/classification-evaluation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# cv = 10 means make 10-folds within the Training set\n",
    "# Cs = 3 means within each fold, make 3 attempts to find best tuning parameter\n",
    "lr_model_CV = LogisticRegressionCV(Cs=3, cv=10, refit=True, class_weight='balanced')\n",
    "\n",
    "lr_model_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_CV_predict = lr_model_CV.predict(X_test)\n",
    "\n",
    "metrics.confusion_matrix(y_test, lr_CV_predict, labels=response_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, lr_CV_predict, labels=response_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
