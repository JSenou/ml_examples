{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing Handwritten Digits\n",
    "### This is taken from the Scikit-learn tutorial at:  http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#example-classification-plot-digits-classification-py\n",
    "### I have added some in-line comments of my own to clarify specific points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# Import the digits dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the shapes of the data and target arrays\n",
    "digits.data.shape, digits.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a list of the images and their targets (to use as labels for a few to be displayed )\n",
    "images_and_labels = list(zip(digits.images, digits.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAB0CAYAAABZjfMMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e4841d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a few of the training images\n",
    "n_ims = 4\n",
    "for index, (image, label) in enumerate(images_and_labels[:n_ims]):\n",
    "    plt.subplot(2, n_ims, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=\"Greys\", interpolation='none')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 8, 8), (1797, 64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "digits.images.shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a classifier: a support vector (with gamma set to 0.001)\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# Train the classifier on the first half of the data\n",
    "X = data[ : n_samples / 2]\n",
    "y = digits.target[ : n_samples / 2 ]\n",
    "classifier.fit( X, y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[ n_samples / 2 : ]\n",
    "T = data[ n_samples / 2 : ]\n",
    "predicted = classifier.predict( T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    }
   ],
   "source": [
    "# check the Confusion matrix & examine the diagonal\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.99      0.97      0.98        91\n",
      "          2       0.99      0.99      0.99        86\n",
      "          3       0.98      0.87      0.92        91\n",
      "          4       0.99      0.96      0.97        92\n",
      "          5       0.95      0.97      0.96        91\n",
      "          6       0.99      0.99      0.99        91\n",
      "          7       0.96      0.99      0.97        89\n",
      "          8       0.94      1.00      0.97        88\n",
      "          9       0.93      0.98      0.95        92\n",
      "\n",
      "avg / total       0.97      0.97      0.97       899\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a Classification report-- the \"recall\" column is a measure of how well the \n",
    "# classifier is predicting each of the ten digits.\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = metrics.classification_report(expected, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'avg / total       0.97      0.97      0.97       899\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-53:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAB0CAYAAACohqiBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11120a0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a look at the agreement between some of the target images and the predicted digit\n",
    "images_and_predictions = list(zip(digits.images[ n_samples / 2 : ], predicted ))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:n_ims]):\n",
    "    plt.subplot(2, n_ims, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a quick, crude fine-tuning gamma-- is the initial choice of 0.001 a good one?  Is there a better one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-05,   3.16227766e-05,   1.00000000e-04,\n",
       "         3.16227766e-04,   1.00000000e-03,   3.16227766e-03,\n",
       "         1.00000000e-02,   3.16227766e-02,   1.00000000e-01,\n",
       "         3.16227766e-01])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a few log-spaced values of gamma from 1.e-05 to 0.1\n",
    "import numpy as np\n",
    "\n",
    "gam = 10.**np.arange(-5,0,0.5) \n",
    "gam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma = 0.00001 --> recall = 0.83 \n",
      "gamma = 0.00003 --> recall = 0.92 \n",
      "gamma = 0.00010 --> recall = 0.94 \n",
      "gamma = 0.00032 --> recall = 0.96 \n",
      "gamma = 0.00100 --> recall = 0.97 \n",
      "gamma = 0.00316 --> recall = 0.95 \n",
      "gamma = 0.01000 --> recall = 0.92 \n",
      "gamma = 0.03162 --> recall = 0.41 \n",
      "gamma = 0.10000 --> recall = 0.01 \n",
      "gamma = 0.31623 --> recall = 0.01 \n"
     ]
    }
   ],
   "source": [
    "for g in gam:\n",
    "    classifier = svm.SVC(gamma=g)\n",
    "\n",
    "    # Train the classifier on the first half of the data\n",
    "    X = data[ : n_samples / 2]\n",
    "    y = digits.target[ : n_samples / 2 ]\n",
    "    classifier.fit( X, y )\n",
    "    expected = digits.target[ n_samples / 2 : ]\n",
    "    T = data[ n_samples / 2 : ]\n",
    "    predicted = classifier.predict( T )\n",
    "    print(\"gamma = {0:.5f} --> recall = {1}\".format(np.around(g,decimals=5),\n",
    "                    metrics.classification_report(expected, predicted)[-35:-30]) )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Okay, gamma = 0.001 turns out be pretty much the best value anyway"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
